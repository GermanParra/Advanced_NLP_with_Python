{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare NLP Techniques: Build Model On word2vec Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read In Cleaned Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned training and test sets\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv('../../../data/X_train.csv')\n",
    "X_test = pd.read_csv('../../../data/X_test.csv')\n",
    "y_train = pd.read_csv('../../../data/y_train.csv')\n",
    "y_test = pd.read_csv('../../../data/y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create word2vec Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a basic word2vec model\n",
    "w2v_model = gensim.models.Word2Vec(X_train,\n",
    "                                   vector_size=100,\n",
    "                                   window=5,\n",
    "                                   min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the words in each text message with the learned word vector\n",
    "words = set(w2v_model.wv.index_to_key)\n",
    "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                         for ls in X_train['clean_text']], dtype=object)\n",
    "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                         for ls in X_test['clean_text']], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average the word vectors for each sentence (and assign a vector of zeros if the model\n",
    "# did not learn any of the words in the text message during training\n",
    "X_train_vect_avg = []\n",
    "for v in X_train_vect:\n",
    "    if v.size:\n",
    "        X_train_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_train_vect_avg.append(np.zeros(100, dtype=float))\n",
    "        \n",
    "X_test_vect_avg = []\n",
    "for v in X_test_vect:\n",
    "    if v.size:\n",
    "        X_test_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_test_vect_avg.append(np.zeros(100, dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.6196875e-03,  3.6657380e-03,  5.1898835e-03,  5.7419371e-03,\n",
       "         7.4669169e-03, -6.1676763e-03,  1.1056137e-03,  6.0472824e-03,\n",
       "        -2.8400517e-03, -6.1735227e-03, -4.1022300e-04, -8.3689503e-03,\n",
       "        -5.6000138e-03,  7.1045374e-03,  3.3525396e-03,  7.2256685e-03,\n",
       "         6.8002464e-03,  7.5307419e-03, -3.7891555e-03, -5.6180713e-04,\n",
       "         2.3483753e-03, -4.5190332e-03,  8.3887316e-03, -9.8581649e-03,\n",
       "         6.7646410e-03,  2.9144168e-03, -4.9328329e-03,  4.3981862e-03,\n",
       "        -1.7395759e-03,  6.7113829e-03,  9.9648498e-03, -4.3624449e-03,\n",
       "        -5.9933902e-04, -5.6956387e-03,  3.8508223e-03,  2.7866268e-03,\n",
       "         6.8910765e-03,  6.1010956e-03,  9.5384959e-03,  9.2734173e-03,\n",
       "         7.8980681e-03, -6.9895051e-03, -9.1558648e-03, -3.5575390e-04,\n",
       "        -3.0998420e-03,  7.8943158e-03,  5.9385728e-03, -1.5456629e-03,\n",
       "         1.5109634e-03,  1.7900396e-03,  7.8175711e-03, -9.5101884e-03,\n",
       "        -2.0553112e-04,  3.4691954e-03, -9.3897345e-04,  8.3817719e-03,\n",
       "         9.0107825e-03,  6.5365052e-03, -7.1162224e-04,  7.7104042e-03,\n",
       "        -8.5343365e-03,  3.2071066e-03, -4.6379971e-03, -5.0889566e-03,\n",
       "         3.5896183e-03,  5.3703380e-03,  7.7695129e-03, -5.7665063e-03,\n",
       "         7.4333595e-03,  6.6254949e-03, -3.7098003e-03, -8.7456414e-03,\n",
       "         5.4374672e-03,  6.5097548e-03, -7.8755140e-04, -6.7098569e-03,\n",
       "        -7.0859264e-03, -2.4970602e-03,  5.1432536e-03, -3.6652375e-03,\n",
       "        -9.3700597e-03,  3.8267397e-03,  4.8844791e-03, -6.4285635e-03,\n",
       "         1.2085581e-03, -2.0748782e-03,  2.4402141e-05, -9.8835090e-03,\n",
       "         2.6920033e-03, -4.7501065e-03,  1.0876465e-03, -1.5762257e-03,\n",
       "         2.1966719e-03, -7.8815771e-03, -2.7171851e-03,  2.6631975e-03,\n",
       "         5.3466819e-03, -2.3915148e-03, -9.5100952e-03,  4.5058774e-03],\n",
       "       [-5.3622725e-04,  2.3643016e-04,  5.1033497e-03,  9.0092728e-03,\n",
       "        -9.3029495e-03, -7.1168090e-03,  6.4588715e-03,  8.9729885e-03,\n",
       "        -5.0154282e-03, -3.7633730e-03,  7.3805046e-03, -1.5334726e-03,\n",
       "        -4.5366143e-03,  6.5540504e-03, -4.8601604e-03, -1.8160177e-03,\n",
       "         2.8765798e-03,  9.9187379e-04, -8.2852151e-03, -9.4488189e-03,\n",
       "         7.3117660e-03,  5.0702621e-03,  6.7576934e-03,  7.6286553e-04,\n",
       "         6.3508893e-03, -3.4053659e-03, -9.4640255e-04,  5.7685734e-03,\n",
       "        -7.5216386e-03, -3.9361049e-03, -7.5115822e-03, -9.3004224e-04,\n",
       "         9.5381187e-03, -7.3191668e-03, -2.3337698e-03, -1.9377422e-03,\n",
       "         8.0774352e-03, -5.9308959e-03,  4.5161247e-05, -4.7537349e-03,\n",
       "        -9.6035507e-03,  5.0072931e-03, -8.7595871e-03, -4.3918253e-03,\n",
       "        -3.5099984e-05, -2.9618264e-04, -7.6612402e-03,  9.6147414e-03,\n",
       "         4.9820566e-03,  9.2331432e-03, -8.1579182e-03,  4.4957972e-03,\n",
       "        -4.1370774e-03,  8.2453492e-04,  8.4986184e-03, -4.4621779e-03,\n",
       "         4.5175003e-03, -6.7869616e-03, -3.5484887e-03,  9.3985079e-03,\n",
       "        -1.5776539e-03,  3.2137157e-04, -4.1406299e-03, -7.6826881e-03,\n",
       "        -1.5080094e-03,  2.4697948e-03, -8.8802812e-04,  5.5336617e-03,\n",
       "        -2.7429771e-03,  2.2600652e-03,  5.4557943e-03,  8.3459523e-03,\n",
       "        -1.4537406e-03, -9.2081428e-03,  4.3705511e-03,  5.7178497e-04,\n",
       "         7.4419067e-03, -8.1328390e-04, -2.6384138e-03, -8.7530091e-03,\n",
       "        -8.5655687e-04,  2.8265619e-03,  5.4014279e-03,  7.0526553e-03,\n",
       "        -5.7031228e-03,  1.8588186e-03,  6.0888622e-03, -4.7980524e-03,\n",
       "        -3.1072616e-03,  6.7976285e-03,  1.6314745e-03,  1.8991709e-04,\n",
       "         3.4736372e-03,  2.1777629e-04,  9.6188262e-03,  5.0606038e-03,\n",
       "        -8.9173913e-03, -7.0415614e-03,  9.0145587e-04,  6.3925339e-03],\n",
       "       [-8.6196875e-03,  3.6657380e-03,  5.1898835e-03,  5.7419371e-03,\n",
       "         7.4669169e-03, -6.1676763e-03,  1.1056137e-03,  6.0472824e-03,\n",
       "        -2.8400517e-03, -6.1735227e-03, -4.1022300e-04, -8.3689503e-03,\n",
       "        -5.6000138e-03,  7.1045374e-03,  3.3525396e-03,  7.2256685e-03,\n",
       "         6.8002464e-03,  7.5307419e-03, -3.7891555e-03, -5.6180713e-04,\n",
       "         2.3483753e-03, -4.5190332e-03,  8.3887316e-03, -9.8581649e-03,\n",
       "         6.7646410e-03,  2.9144168e-03, -4.9328329e-03,  4.3981862e-03,\n",
       "        -1.7395759e-03,  6.7113829e-03,  9.9648498e-03, -4.3624449e-03,\n",
       "        -5.9933902e-04, -5.6956387e-03,  3.8508223e-03,  2.7866268e-03,\n",
       "         6.8910765e-03,  6.1010956e-03,  9.5384959e-03,  9.2734173e-03,\n",
       "         7.8980681e-03, -6.9895051e-03, -9.1558648e-03, -3.5575390e-04,\n",
       "        -3.0998420e-03,  7.8943158e-03,  5.9385728e-03, -1.5456629e-03,\n",
       "         1.5109634e-03,  1.7900396e-03,  7.8175711e-03, -9.5101884e-03,\n",
       "        -2.0553112e-04,  3.4691954e-03, -9.3897345e-04,  8.3817719e-03,\n",
       "         9.0107825e-03,  6.5365052e-03, -7.1162224e-04,  7.7104042e-03,\n",
       "        -8.5343365e-03,  3.2071066e-03, -4.6379971e-03, -5.0889566e-03,\n",
       "         3.5896183e-03,  5.3703380e-03,  7.7695129e-03, -5.7665063e-03,\n",
       "         7.4333595e-03,  6.6254949e-03, -3.7098003e-03, -8.7456414e-03,\n",
       "         5.4374672e-03,  6.5097548e-03, -7.8755140e-04, -6.7098569e-03,\n",
       "        -7.0859264e-03, -2.4970602e-03,  5.1432536e-03, -3.6652375e-03,\n",
       "        -9.3700597e-03,  3.8267397e-03,  4.8844791e-03, -6.4285635e-03,\n",
       "         1.2085581e-03, -2.0748782e-03,  2.4402141e-05, -9.8835090e-03,\n",
       "         2.6920033e-03, -4.7501065e-03,  1.0876465e-03, -1.5762257e-03,\n",
       "         2.1966719e-03, -7.8815771e-03, -2.7171851e-03,  2.6631975e-03,\n",
       "         5.3466819e-03, -2.3915148e-03, -9.5100952e-03,  4.5058774e-03],\n",
       "       [-5.3622725e-04,  2.3643016e-04,  5.1033497e-03,  9.0092728e-03,\n",
       "        -9.3029495e-03, -7.1168090e-03,  6.4588715e-03,  8.9729885e-03,\n",
       "        -5.0154282e-03, -3.7633730e-03,  7.3805046e-03, -1.5334726e-03,\n",
       "        -4.5366143e-03,  6.5540504e-03, -4.8601604e-03, -1.8160177e-03,\n",
       "         2.8765798e-03,  9.9187379e-04, -8.2852151e-03, -9.4488189e-03,\n",
       "         7.3117660e-03,  5.0702621e-03,  6.7576934e-03,  7.6286553e-04,\n",
       "         6.3508893e-03, -3.4053659e-03, -9.4640255e-04,  5.7685734e-03,\n",
       "        -7.5216386e-03, -3.9361049e-03, -7.5115822e-03, -9.3004224e-04,\n",
       "         9.5381187e-03, -7.3191668e-03, -2.3337698e-03, -1.9377422e-03,\n",
       "         8.0774352e-03, -5.9308959e-03,  4.5161247e-05, -4.7537349e-03,\n",
       "        -9.6035507e-03,  5.0072931e-03, -8.7595871e-03, -4.3918253e-03,\n",
       "        -3.5099984e-05, -2.9618264e-04, -7.6612402e-03,  9.6147414e-03,\n",
       "         4.9820566e-03,  9.2331432e-03, -8.1579182e-03,  4.4957972e-03,\n",
       "        -4.1370774e-03,  8.2453492e-04,  8.4986184e-03, -4.4621779e-03,\n",
       "         4.5175003e-03, -6.7869616e-03, -3.5484887e-03,  9.3985079e-03,\n",
       "        -1.5776539e-03,  3.2137157e-04, -4.1406299e-03, -7.6826881e-03,\n",
       "        -1.5080094e-03,  2.4697948e-03, -8.8802812e-04,  5.5336617e-03,\n",
       "        -2.7429771e-03,  2.2600652e-03,  5.4557943e-03,  8.3459523e-03,\n",
       "        -1.4537406e-03, -9.2081428e-03,  4.3705511e-03,  5.7178497e-04,\n",
       "         7.4419067e-03, -8.1328390e-04, -2.6384138e-03, -8.7530091e-03,\n",
       "        -8.5655687e-04,  2.8265619e-03,  5.4014279e-03,  7.0526553e-03,\n",
       "        -5.7031228e-03,  1.8588186e-03,  6.0888622e-03, -4.7980524e-03,\n",
       "        -3.1072616e-03,  6.7976285e-03,  1.6314745e-03,  1.8991709e-04,\n",
       "         3.4736372e-03,  2.1777629e-04,  9.6188262e-03,  5.0606038e-03,\n",
       "        -8.9173913e-03, -7.0415614e-03,  9.0145587e-04,  6.3925339e-03],\n",
       "       [-5.3622725e-04,  2.3643016e-04,  5.1033497e-03,  9.0092728e-03,\n",
       "        -9.3029495e-03, -7.1168090e-03,  6.4588715e-03,  8.9729885e-03,\n",
       "        -5.0154282e-03, -3.7633730e-03,  7.3805046e-03, -1.5334726e-03,\n",
       "        -4.5366143e-03,  6.5540504e-03, -4.8601604e-03, -1.8160177e-03,\n",
       "         2.8765798e-03,  9.9187379e-04, -8.2852151e-03, -9.4488189e-03,\n",
       "         7.3117660e-03,  5.0702621e-03,  6.7576934e-03,  7.6286553e-04,\n",
       "         6.3508893e-03, -3.4053659e-03, -9.4640255e-04,  5.7685734e-03,\n",
       "        -7.5216386e-03, -3.9361049e-03, -7.5115822e-03, -9.3004224e-04,\n",
       "         9.5381187e-03, -7.3191668e-03, -2.3337698e-03, -1.9377422e-03,\n",
       "         8.0774352e-03, -5.9308959e-03,  4.5161247e-05, -4.7537349e-03,\n",
       "        -9.6035507e-03,  5.0072931e-03, -8.7595871e-03, -4.3918253e-03,\n",
       "        -3.5099984e-05, -2.9618264e-04, -7.6612402e-03,  9.6147414e-03,\n",
       "         4.9820566e-03,  9.2331432e-03, -8.1579182e-03,  4.4957972e-03,\n",
       "        -4.1370774e-03,  8.2453492e-04,  8.4986184e-03, -4.4621779e-03,\n",
       "         4.5175003e-03, -6.7869616e-03, -3.5484887e-03,  9.3985079e-03,\n",
       "        -1.5776539e-03,  3.2137157e-04, -4.1406299e-03, -7.6826881e-03,\n",
       "        -1.5080094e-03,  2.4697948e-03, -8.8802812e-04,  5.5336617e-03,\n",
       "        -2.7429771e-03,  2.2600652e-03,  5.4557943e-03,  8.3459523e-03,\n",
       "        -1.4537406e-03, -9.2081428e-03,  4.3705511e-03,  5.7178497e-04,\n",
       "         7.4419067e-03, -8.1328390e-04, -2.6384138e-03, -8.7530091e-03,\n",
       "        -8.5655687e-04,  2.8265619e-03,  5.4014279e-03,  7.0526553e-03,\n",
       "        -5.7031228e-03,  1.8588186e-03,  6.0888622e-03, -4.7980524e-03,\n",
       "        -3.1072616e-03,  6.7976285e-03,  1.6314745e-03,  1.8991709e-04,\n",
       "         3.4736372e-03,  2.1777629e-04,  9.6188262e-03,  5.0606038e-03,\n",
       "        -8.9173913e-03, -7.0415614e-03,  9.0145587e-04,  6.3925339e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does the unaveraged version look like?\n",
    "X_train_vect[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.7696115e-03,  1.6081532e-03,  5.1379632e-03,  7.7023380e-03,\n",
       "       -2.5950030e-03, -6.7371563e-03,  4.3175681e-03,  7.8027053e-03,\n",
       "       -4.1452772e-03, -4.7274330e-03,  4.2642136e-03, -4.2676637e-03,\n",
       "       -4.9619740e-03,  6.7742453e-03, -1.5750803e-03,  1.8006569e-03,\n",
       "        4.4460464e-03,  3.6074209e-03, -6.4867912e-03, -5.8940141e-03,\n",
       "        5.3264098e-03,  1.2345440e-03,  7.4101090e-03, -3.4855469e-03,\n",
       "        6.5163905e-03, -8.7745284e-04, -2.5409746e-03,  5.2204183e-03,\n",
       "       -5.2088136e-03,  3.2289009e-04, -5.2100944e-04, -2.3030031e-03,\n",
       "        5.4831356e-03, -6.6697551e-03,  1.4006710e-04, -4.7994639e-05,\n",
       "        7.6028914e-03, -1.1180993e-03,  3.8424954e-03,  8.5712597e-04,\n",
       "       -2.6029032e-03,  2.0857379e-04, -8.9180982e-03, -2.7773969e-03,\n",
       "       -1.2609968e-03,  2.9800166e-03, -2.2213149e-03,  5.1505798e-03,\n",
       "        3.5936192e-03,  6.2559014e-03, -1.7677225e-03, -1.1065968e-03,\n",
       "       -2.5644589e-03,  1.8823992e-03,  4.7235815e-03,  6.7540200e-04,\n",
       "        6.3148127e-03, -1.4575749e-03, -2.4137422e-03,  8.7232664e-03,\n",
       "       -4.3603266e-03,  1.4756655e-03, -4.3395767e-03, -6.6451952e-03,\n",
       "        5.3104165e-04,  3.6300118e-03,  2.5749882e-03,  1.0135944e-03,\n",
       "        1.3275577e-03,  4.0062373e-03,  1.7895565e-03,  1.5093148e-03,\n",
       "        1.3027426e-03, -2.9209838e-03,  2.3073100e-03, -2.3408718e-03,\n",
       "        1.6307734e-03, -1.4867944e-03,  4.7425326e-04, -6.7179007e-03,\n",
       "       -4.2619579e-03,  3.2266330e-03,  5.1946482e-03,  1.6601678e-03,\n",
       "       -2.9384505e-03,  2.8533986e-04,  3.6630780e-03, -6.8322355e-03,\n",
       "       -7.8755559e-04,  2.1785344e-03,  1.4139434e-03, -5.1654002e-04,\n",
       "        2.9628512e-03, -3.0219648e-03,  4.6844217e-03,  4.1016415e-03,\n",
       "       -3.2117621e-03, -5.1815426e-03, -3.2631650e-03,  5.6378716e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does the averaged version look like?\n",
    "X_train_vect_avg[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit RandomForestClassifier On Top Of Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit a basic Random Forest model on top of the vectors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_model = rf.fit(X_train_vect_avg, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to make predictions on the test data\n",
    "y_pred = rf_model.predict(X_test_vect_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.559 / Recall: 0.204 / Accuracy: 0.861\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions of the model on the holdout test set\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(precision, 3), round(recall, 3), round((y_pred==y_test['label']).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
